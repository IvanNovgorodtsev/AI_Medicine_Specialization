{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import backend as K \n",
    "\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set home directory and data directory\n",
    "HOME_DIR = \"./BraTS-Data/\"\n",
    "DATA_DIR = HOME_DIR\n",
    "\n",
    "def load_case(image_nifty_file, label_nifty_file):\n",
    "    # load the image and label file, get the image content and return a numpy array for each\n",
    "    image = np.array(nib.load(image_nifty_file).get_fdata())\n",
    "    label = np.array(nib.load(label_nifty_file).get_fdata())\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = load_case(DATA_DIR + \"imagesTr/BRATS_003.nii.gz\", DATA_DIR + \"labelsTr/BRATS_003.nii.gz\")\n",
    "image = util.get_labeled_image(image, label)\n",
    "\n",
    "util.plot_image_grid(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = load_case(DATA_DIR + \"imagesTr/BRATS_003.nii.gz\", DATA_DIR + \"labelsTr/BRATS_003.nii.gz\")\n",
    "util.visualize_data_gif(util.get_labeled_image(image, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def get_sub_volume(image, label, \n",
    "                   orig_x = 240, orig_y = 240, orig_z = 155, \n",
    "                   output_x = 160, output_y = 160, output_z = 16,\n",
    "                   num_classes = 4, max_tries = 1000, \n",
    "                   background_threshold=0.95):\n",
    "    \"\"\"\n",
    "    Extract random sub-volume from original images.\n",
    "\n",
    "    Args:\n",
    "        image (np.array): original image, \n",
    "            of shape (orig_x, orig_y, orig_z, num_channels)\n",
    "        label (np.array): original label. \n",
    "            labels coded using discrete values rather than\n",
    "            a separate dimension, \n",
    "            so this is of shape (orig_x, orig_y, orig_z)\n",
    "        orig_x (int): x_dim of input image\n",
    "        orig_y (int): y_dim of input image\n",
    "        orig_z (int): z_dim of input image\n",
    "        output_x (int): desired x_dim of output\n",
    "        output_y (int): desired y_dim of output\n",
    "        output_z (int): desired z_dim of output\n",
    "        num_classes (int): number of class labels\n",
    "        max_tries (int): maximum trials to do when sampling\n",
    "        background_threshold (float): limit on the fraction \n",
    "            of the sample which can be the background\n",
    "\n",
    "    returns:\n",
    "        X (np.array): sample of original image of dimension \n",
    "            (num_channels, output_x, output_y, output_z)\n",
    "        y (np.array): labels which correspond to X, of dimension \n",
    "            (num_classes, output_x, output_y, output_z)\n",
    "    \"\"\"\n",
    "    # Initialize features and labels with `None`\n",
    "    X = None\n",
    "    y = None\n",
    "\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    tries = 0\n",
    "    \n",
    "    while tries < max_tries:\n",
    "        # randomly sample sub-volume by sampling the corner voxel\n",
    "        # hint: make sure to leave enough room for the output dimensions!\n",
    "        start_x = np.random.randint(orig_x - output_x + 1 )\n",
    "        start_y = np.random.randint(orig_y - output_y + 1 )\n",
    "        start_z = np.random.randint(orig_z - output_z + 1 )\n",
    "\n",
    "        # extract relevant area of label\n",
    "        y = label[start_x: start_x + output_x,\n",
    "                  start_y: start_y + output_y,\n",
    "                  start_z: start_z + output_z]\n",
    "        \n",
    "        # One-hot encode the categories.\n",
    "        # This adds a 4th dimension, 'num_classes'\n",
    "        # (output_x, output_y, output_z, num_classes)\n",
    "        y = keras.utils.to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "        # compute the background ratio\n",
    "        bgrd_ratio = np.sum(y[...,0])/(output_x*output_y*output_z)\n",
    "\n",
    "        # increment tries counter\n",
    "        tries += 1\n",
    "\n",
    "        # if background ratio is below the desired threshold,\n",
    "        # use that sub-volume.\n",
    "        # otherwise continue the loop and try another random sub-volume\n",
    "        if bgrd_ratio < background_threshold:\n",
    "\n",
    "            # make copy of the sub-volume\n",
    "            X = np.copy(image[start_x: start_x + output_x,\n",
    "                              start_y: start_y + output_y,\n",
    "                              start_z: start_z + output_z, :])\n",
    "            \n",
    "            # change dimension of X\n",
    "            # from (x_dim, y_dim, z_dim, num_channels)\n",
    "            # to (num_channels, x_dim, y_dim, z_dim)\n",
    "            X = np.moveaxis(X,-1, 0)\n",
    "\n",
    "            # change dimension of y\n",
    "            # from (x_dim, y_dim, z_dim, num_classes)\n",
    "            # to (num_classes, x_dim, y_dim, z_dim)\n",
    "            y = np.moveaxis(y, -1, 0)\n",
    "\n",
    "            ### END CODE HERE ###\n",
    "            \n",
    "            # take a subset of y that excludes the background class\n",
    "            # in the 'num_classes' dimension\n",
    "            y = y[1:, :, :, :]\n",
    "    \n",
    "            return X, y\n",
    "\n",
    "    # if we've tried max_tries number of samples\n",
    "    # Give up in order to avoid looping forever.\n",
    "    print(f\"Tried {tries} times to find a sub-volume. Giving up...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "\n",
    "image = np.zeros((4, 4, 3, 1))\n",
    "label = np.zeros((4, 4, 3))\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        for k in range(3):\n",
    "            image[i, j, k, 0] = i*j*k\n",
    "            label[i, j, k] = k\n",
    "\n",
    "print(\"image:\")\n",
    "for k in range(3):\n",
    "    print(f\"z = {k}\")\n",
    "    print(image[:, :, k, 0])\n",
    "print(\"\\n\")\n",
    "print(\"label:\")\n",
    "for k in range(3):\n",
    "    print(f\"z = {k}\")\n",
    "    print(label[:, :, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image, sample_label = get_sub_volume(image, \n",
    "                                            label,\n",
    "                                            orig_x=4, \n",
    "                                            orig_y=4, \n",
    "                                            orig_z=3,\n",
    "                                            output_x=2, \n",
    "                                            output_y=2, \n",
    "                                            output_z=2,\n",
    "                                            num_classes = 3)\n",
    "\n",
    "print(\"Sampled Image:\")\n",
    "for k in range(2):\n",
    "    print(\"z = \" + str(k))\n",
    "    print(sample_image[0, :, :, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sampled Label:\")\n",
    "for c in range(2):\n",
    "    print(\"class = \" + str(c))\n",
    "    for k in range(2):\n",
    "        print(\"z = \" + str(k))\n",
    "        print(sample_label[c, :, :, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = load_case(DATA_DIR + \"imagesTr/BRATS_001.nii.gz\", DATA_DIR + \"labelsTr/BRATS_001.nii.gz\")\n",
    "X, y = get_sub_volume(image, label)\n",
    "# enhancing tumor is channel 2 in the class label\n",
    "# you can change indexer for y to look at different classes\n",
    "util.visualize_patch(X[0, :, :, :], y[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def standardize(image):\n",
    "    \"\"\"\n",
    "    Standardize mean and standard deviation \n",
    "        of each channel and z_dimension.\n",
    "\n",
    "    Args:\n",
    "        image (np.array): input image, \n",
    "            shape (num_channels, dim_x, dim_y, dim_z)\n",
    "\n",
    "    Returns:\n",
    "        standardized_image (np.array): standardized version of input image\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # initialize to array of zeros, with same shape as the image\n",
    "    standardized_image = np.zeros(image.shape)\n",
    "\n",
    "    # iterate over channels\n",
    "    for c in range(image.shape[0]):\n",
    "        # iterate over the `z` dimension\n",
    "        for z in range(image.shape[3]):\n",
    "            # get a slice of the image \n",
    "            # at channel c and z-th dimension `z`\n",
    "            image_slice = image[c,:,:,z]\n",
    "\n",
    "            # subtract the mean from image_slice\n",
    "            centered = image_slice - np.mean(image_slice)\n",
    "\n",
    "            if image_slice.std() != 0:\n",
    "                centered_scaled = centered/np.std(image_slice)\n",
    "            else:\n",
    "                centered_scaled = centered\n",
    "\n",
    "            # update  the slice of standardized image\n",
    "            # with the scaled centered and scaled image\n",
    "            standardized_image[c, :, :, z] = centered_scaled\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return standardized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = standardize(X)\n",
    "print(\"standard deviation for a slice should be 1.0\")\n",
    "print(f\"stddv for X_norm[0, :, :, 0]: {X_norm[0,:,:,0].std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.visualize_patch(X_norm[0, :, :, :], y[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def single_class_dice_coefficient(y_true, y_pred, axis=(0, 1, 2), \n",
    "                                  epsilon=0.00001):\n",
    "    \"\"\"\n",
    "    Compute dice coefficient for single class.\n",
    "\n",
    "    Args:\n",
    "        y_true (Tensorflow tensor): tensor of ground truth values for single class.\n",
    "                                    shape: (x_dim, y_dim, z_dim)\n",
    "        y_pred (Tensorflow tensor): tensor of predictions for single class.\n",
    "                                    shape: (x_dim, y_dim, z_dim)\n",
    "        axis (tuple): spatial axes to sum over when computing numerator and\n",
    "                      denominator of dice coefficient.\n",
    "                      Hint: pass this as the 'axis' argument to the K.sum function.\n",
    "        epsilon (float): small constant added to numerator and denominator to\n",
    "                        avoid divide by 0 errors.\n",
    "    Returns:\n",
    "        dice_coefficient (float): computed value of dice coefficient.     \n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    dice_numerator = 2*K.sum(y_true*y_pred,axis=axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true,axis= axis) + K.sum(y_pred, axis = axis) + epsilon\n",
    "    dice_coefficient = dice_numerator / dice_denominator\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return dice_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST CASES\n",
    "sess = K.get_session()\n",
    "#sess = tf.compat.v1.Session()\n",
    "with sess.as_default() as sess:\n",
    "    pred = np.expand_dims(np.eye(2), -1)\n",
    "    label = np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), -1)\n",
    "\n",
    "    print(\"Test Case #1\")\n",
    "    print(\"pred:\")\n",
    "    print(pred[:, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(label[:, :, 0])\n",
    "\n",
    "    # choosing a large epsilon to help check for implementation errors\n",
    "    dc = single_class_dice_coefficient(pred, label,epsilon=1)\n",
    "    print(f\"dice coefficient: {dc.eval():.4f}\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Test Case #2\")\n",
    "    pred = np.expand_dims(np.eye(2), -1)\n",
    "    label = np.expand_dims(np.array([[1.0, 1.0], [0.0, 1.0]]), -1)\n",
    "\n",
    "    print(\"pred:\")\n",
    "    print(pred[:, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(label[:, :, 0])\n",
    "\n",
    "    # choosing a large epsilon to help check for implementation errors\n",
    "    dc = single_class_dice_coefficient(pred, label,epsilon=1)\n",
    "    print(f\"dice_coefficient: {dc.eval():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def dice_coefficient(y_true, y_pred, axis=(1, 2, 3), \n",
    "                     epsilon=0.00001):\n",
    "    \"\"\"\n",
    "    Compute mean dice coefficient over all abnormality classes.\n",
    "\n",
    "    Args:\n",
    "        y_true (Tensorflow tensor): tensor of ground truth values for all classes.\n",
    "                                    shape: (num_classes, x_dim, y_dim, z_dim)\n",
    "        y_pred (Tensorflow tensor): tensor of predictions for all classes.\n",
    "                                    shape: (num_classes, x_dim, y_dim, z_dim)\n",
    "        axis (tuple): spatial axes to sum over when computing numerator and\n",
    "                      denominator of dice coefficient.\n",
    "                      Hint: pass this as the 'axis' argument to the K.sum\n",
    "                            and K.mean functions.\n",
    "        epsilon (float): small constant add to numerator and denominator to\n",
    "                        avoid divide by 0 errors.\n",
    "    Returns:\n",
    "        dice_coefficient (float): computed value of dice coefficient.     \n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    dice_numerator = 2*K.sum(y_true*y_pred,axis=axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true,axis= axis) + K.sum(y_pred, axis = axis) + epsilon\n",
    "    dice_coefficient = K.mean(dice_numerator / dice_denominator,axis = 0)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return dice_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST CASES\n",
    "sess = K.get_session()\n",
    "with sess.as_default() as sess:\n",
    "    pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\n",
    "    label = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), 0), -1)\n",
    "\n",
    "    print(\"Test Case #1\")\n",
    "    print(\"pred:\")\n",
    "    print(pred[0, :, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(label[0, :, :, 0])\n",
    "\n",
    "    dc = dice_coefficient(pred, label,epsilon=1)\n",
    "    print(f\"dice coefficient: {dc.eval():.4f}\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Test Case #2\")\n",
    "    pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\n",
    "    label = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 1.0]]), 0), -1)\n",
    "\n",
    "\n",
    "    print(\"pred:\")\n",
    "    print(pred[0, :, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(label[0, :, :, 0])\n",
    "\n",
    "    dc = dice_coefficient(pred, label,epsilon=1)\n",
    "    print(f\"dice coefficient: {dc.eval():.4f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "    print(\"Test Case #3\")\n",
    "    pred = np.zeros((2, 2, 2, 1))\n",
    "    pred[0, :, :, :] = np.expand_dims(np.eye(2), -1)\n",
    "    pred[1, :, :, :] = np.expand_dims(np.eye(2), -1)\n",
    "    \n",
    "    label = np.zeros((2, 2, 2, 1))\n",
    "    label[0, :, :, :] = np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), -1)\n",
    "    label[1, :, :, :] = np.expand_dims(np.array([[1.0, 1.0], [0.0, 1.0]]), -1)\n",
    "\n",
    "    print(\"pred:\")\n",
    "    print(\"class = 0\")\n",
    "    print(pred[0, :, :, 0])\n",
    "    print(\"class = 1\")\n",
    "    print(pred[1, :, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(\"class = 0\")\n",
    "    print(label[0, :, :, 0])\n",
    "    print(\"class = 1\")\n",
    "    print(label[1, :, :, 0])\n",
    "\n",
    "    dc = dice_coefficient(pred, label,epsilon=1)\n",
    "    print(f\"dice coefficient: {dc.eval():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def soft_dice_loss(y_true, y_pred, axis=(1, 2, 3), \n",
    "                   epsilon=0.00001):\n",
    "    \"\"\"\n",
    "    Compute mean soft dice loss over all abnormality classes.\n",
    "\n",
    "    Args:\n",
    "        y_true (Tensorflow tensor): tensor of ground truth values for all classes.\n",
    "                                    shape: (num_classes, x_dim, y_dim, z_dim)\n",
    "        y_pred (Tensorflow tensor): tensor of soft predictions for all classes.\n",
    "                                    shape: (num_classes, x_dim, y_dim, z_dim)\n",
    "        axis (tuple): spatial axes to sum over when computing numerator and\n",
    "                      denominator in formula for dice loss.\n",
    "                      Hint: pass this as the 'axis' argument to the K.sum\n",
    "                            and K.mean functions.\n",
    "        epsilon (float): small constant added to numerator and denominator to\n",
    "                        avoid divide by 0 errors.\n",
    "    Returns:\n",
    "        dice_loss (float): computed value of dice loss.     \n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "\n",
    "    dice_numerator = 2 * K.sum(y_true * y_pred, axis=axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true*y_true,axis=axis) + K.sum(y_pred*y_pred, axis=axis) + epsilon\n",
    "    dice_loss = 1 - K.mean(dice_numerator / dice_denominator, axis = 0)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST CASES\n",
    "sess = K.get_session()\n",
    "with sess.as_default() as sess:\n",
    "    pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\n",
    "    label = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), 0), -1)\n",
    "\n",
    "    print(\"Test Case #1\")\n",
    "    print(\"pred:\")\n",
    "    print(pred[0, :, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(label[0, :, :, 0])\n",
    "\n",
    "    dc = soft_dice_loss(pred, label, epsilon=1)\n",
    "    print(f\"soft dice loss:{dc.eval():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "with sess.as_default() as sess:\n",
    "    pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\n",
    "    label = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), 0), -1)\n",
    "    \n",
    "    print(\"Test Case #2\")\n",
    "    pred = np.expand_dims(np.expand_dims(0.5*np.eye(2), 0), -1)\n",
    "    print(\"pred:\")\n",
    "    print(pred[0, :, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(label[0, :, :, 0])\n",
    "    dc = soft_dice_loss(pred, label, epsilon=1)\n",
    "    print(f\"soft dice loss: {dc.eval():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "with sess.as_default() as sess:\n",
    "    pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\n",
    "    label = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), 0), -1)\n",
    "    \n",
    "    print(\"Test Case #3\")\n",
    "    pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\n",
    "    label = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 1.0]]), 0), -1)\n",
    "\n",
    "    print(\"pred:\")\n",
    "    print(pred[0, :, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(label[0, :, :, 0])\n",
    "\n",
    "    dc = soft_dice_loss(pred, label, epsilon=1)\n",
    "    print(f\"soft dice loss: {dc.eval():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "with sess.as_default() as sess:\n",
    "    pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\n",
    "    label = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), 0), -1)\n",
    "\n",
    "    print(\"Test Case #4\")\n",
    "    pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\n",
    "    pred[0, 0, 1, 0] = 0.8\n",
    "    label = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 1.0]]), 0), -1)\n",
    "\n",
    "    print(\"pred:\")\n",
    "    print(pred[0, :, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(label[0, :, :, 0])\n",
    "\n",
    "    dc = soft_dice_loss(pred, label, epsilon=1)\n",
    "    print(f\"soft dice loss: {dc.eval():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "with sess.as_default() as sess:\n",
    "    pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\n",
    "    label = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), 0), -1)\n",
    "    \n",
    "    print(\"Test Case #5\")\n",
    "    pred = np.zeros((2, 2, 2, 1))\n",
    "    pred[0, :, :, :] = np.expand_dims(0.5*np.eye(2), -1)\n",
    "    pred[1, :, :, :] = np.expand_dims(np.eye(2), -1)\n",
    "    pred[1, 0, 1, 0] = 0.8\n",
    "\n",
    "    label = np.zeros((2, 2, 2, 1))\n",
    "    label[0, :, :, :] = np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), -1)\n",
    "    label[1, :, :, :] = np.expand_dims(np.array([[1.0, 1.0], [0.0, 1.0]]), -1)\n",
    "\n",
    "    print(\"pred:\")\n",
    "    print(\"class = 0\")\n",
    "    print(pred[0, :, :, 0])\n",
    "    print(\"class = 1\")\n",
    "    print(pred[1, :, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(\"class = 0\")\n",
    "    print(label[0, :, :, 0])\n",
    "    print(\"class = 1\")\n",
    "    print(label[1, :, :, 0])\n",
    "\n",
    "    dc = soft_dice_loss(pred, label, epsilon=1)\n",
    "    print(f\"soft dice loss: {dc.eval():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case 6\n",
    "pred = np.array([\n",
    "                    [\n",
    "                        [ \n",
    "                            [1.0, 1.0], [0.0, 0.0]\n",
    "                        ],\n",
    "                        [\n",
    "                            [1.0, 0.0], [0.0, 1.0]\n",
    "                        ]\n",
    "                    ],\n",
    "                    [\n",
    "                        [ \n",
    "                            [1.0, 1.0], [0.0, 0.0]\n",
    "                        ],\n",
    "                        [\n",
    "                            [1.0, 0.0], [0.0, 1.0]\n",
    "                        ]\n",
    "                    ],\n",
    "                  ])\n",
    "label = np.array([\n",
    "                    [\n",
    "                        [ \n",
    "                            [1.0, 0.0], [1.0, 0.0]\n",
    "                        ],\n",
    "                        [\n",
    "                            [1.0, 0.0], [0.0, 0.0]\n",
    "                        ]\n",
    "                    ],\n",
    "                    [\n",
    "                        [ \n",
    "                            [0.0, 0.0], [0.0, 0.0]\n",
    "                        ],\n",
    "                        [\n",
    "                            [1.0, 0.0], [0.0, 0.0]\n",
    "                        ]\n",
    "                    ]\n",
    "                  ])\n",
    "\n",
    "sess = K.get_session()\n",
    "print(\"Test case #6\")\n",
    "with sess.as_default() as sess:\n",
    "    dc = soft_dice_loss(pred, label, epsilon=1)\n",
    "    print(f\"soft dice loss\",dc.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell if you didn't run the training cell in section 4.1\n",
    "base_dir = HOME_DIR + \"processed/\"\n",
    "with open(base_dir + \"config.json\") as json_file:\n",
    "    config = json.load(json_file)\n",
    "# Get generators for training and validation sets\n",
    "train_generator = util.VolumeDataGenerator(config[\"train\"], base_dir + \"train/\", batch_size=3, dim=(160, 160, 16), verbose=0)\n",
    "valid_generator = util.VolumeDataGenerator(config[\"valid\"], base_dir + \"valid/\", batch_size=3, dim=(160, 160, 16), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(HOME_DIR + \"model_pretrained.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.visualize_patch(X_norm[0, :, :, :], y[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm_with_batch_dimension = np.expand_dims(X_norm, axis=0)\n",
    "patch_pred = model.predict(X_norm_with_batch_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set threshold.\n",
    "threshold = 0.5\n",
    "\n",
    "# use threshold to get hard predictions\n",
    "patch_pred[patch_pred > threshold] = 1.0\n",
    "patch_pred[patch_pred <= threshold] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Patch and ground truth\")\n",
    "util.visualize_patch(X_norm[0, :, :, :], y[2])\n",
    "plt.show()\n",
    "print(\"Patch and prediction\")\n",
    "util.visualize_patch(X_norm[0, :, :, :], patch_pred[0, 2, :, :, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def compute_class_sens_spec(pred, label, class_num):\n",
    "    \"\"\"\n",
    "    Compute sensitivity and specificity for a particular example\n",
    "    for a given class.\n",
    "\n",
    "    Args:\n",
    "        pred (np.array): binary arrary of predictions, shape is\n",
    "                         (num classes, height, width, depth).\n",
    "        label (np.array): binary array of labels, shape is\n",
    "                          (num classes, height, width, depth).\n",
    "        class_num (int): number between 0 - (num_classes -1) which says\n",
    "                         which prediction class to compute statistics\n",
    "                         for.\n",
    "\n",
    "    Returns:\n",
    "        sensitivity (float): precision for given class_num.\n",
    "        specificity (float): recall for given class_num\n",
    "    \"\"\"\n",
    "\n",
    "    # extract sub-array for specified class\n",
    "    class_pred = pred[class_num]\n",
    "    class_label = label[class_num]\n",
    "\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # compute:\n",
    "    \n",
    "    # true positives\n",
    "    tp = np.sum((class_label == 1) & (class_pred == 1))\n",
    "\n",
    "    # true negatives\n",
    "    tn = np.sum((class_label == 0) & (class_pred == 0))\n",
    "    \n",
    "    #false positives\n",
    "    fp = np.sum((class_label == 0) & (class_pred == 1))\n",
    "    \n",
    "    # false negatives\n",
    "    fn = np.sum((class_label == 1) & (class_pred == 0))\n",
    "\n",
    "    # compute sensitivity and specificity\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return sensitivity, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST CASES\n",
    "pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\n",
    "label = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), 0), -1)\n",
    "\n",
    "print(\"Test Case #1\")\n",
    "print(\"pred:\")\n",
    "print(pred[0, :, :, 0])\n",
    "print(\"label:\")\n",
    "print(label[0, :, :, 0])\n",
    "\n",
    "sensitivity, specificity = compute_class_sens_spec(pred, label, 0)\n",
    "print(f\"sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"specificity: {specificity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Case #2\")\n",
    "\n",
    "pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\n",
    "label = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 1.0]]), 0), -1)\n",
    "\n",
    "print(\"pred:\")\n",
    "print(pred[0, :, :, 0])\n",
    "print(\"label:\")\n",
    "print(label[0, :, :, 0])\n",
    "\n",
    "sensitivity, specificity = compute_class_sens_spec(pred, label, 0)\n",
    "print(f\"sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"specificity: {specificity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: we must explicity import 'display' in order for the autograder to compile the submitted code\n",
    "# Even though we could use this function without importing it, keep this import in order to allow the grader to work\n",
    "from IPython.display import display\n",
    "print(\"Test Case #3\")\n",
    "\n",
    "df = pd.DataFrame({'y_test': [1,1,0,0,0,0,0,0,0,1,1,1,1,1],\n",
    "                   'preds_test': [1,1,0,0,0,1,1,1,1,0,0,0,0,0],\n",
    "                   'category': ['TP','TP','TN','TN','TN','FP','FP','FP','FP','FN','FN','FN','FN','FN']\n",
    "                  })\n",
    "\n",
    "display(df)\n",
    "pred = np.array( [df['preds_test']])\n",
    "label = np.array( [df['y_test']])\n",
    "\n",
    "sensitivity, specificity = compute_class_sens_spec(pred, label, 0)\n",
    "print(f\"sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"specificity: {specificity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity, specificity = compute_class_sens_spec(patch_pred[0], y, 2)\n",
    "\n",
    "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sens_spec_df(pred, label):\n",
    "    patch_metrics = pd.DataFrame(\n",
    "        columns = ['Edema', \n",
    "                   'Non-Enhancing Tumor', \n",
    "                   'Enhancing Tumor'], \n",
    "        index = ['Sensitivity',\n",
    "                 'Specificity'])\n",
    "    \n",
    "    for i, class_name in enumerate(patch_metrics.columns):\n",
    "        sens, spec = compute_class_sens_spec(pred, label, i)\n",
    "        patch_metrics.loc['Sensitivity', class_name] = round(sens,4)\n",
    "        patch_metrics.loc['Specificity', class_name] = round(spec,4)\n",
    "\n",
    "    return patch_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_sens_spec_df(patch_pred[0], y)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = load_case(DATA_DIR + \"imagesTr/BRATS_003.nii.gz\", DATA_DIR + \"labelsTr/BRATS_003.nii.gz\")\n",
    "pred = util.predict_and_viz(image, label, model, .5, loc=(130, 130, 77))             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_scan_label = keras.utils.to_categorical(label, num_classes = 4)\n",
    "whole_scan_pred = pred\n",
    "\n",
    "# move axis to match shape expected in functions\n",
    "whole_scan_label = np.moveaxis(whole_scan_label, 3 ,0)[1:4]\n",
    "whole_scan_pred = np.moveaxis(whole_scan_pred, 3, 0)[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_scan_df = get_sens_spec_df(whole_scan_pred, whole_scan_label)\n",
    "\n",
    "print(whole_scan_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
